{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d90bc1b8-894f-4433-86d7-1d7c7be67e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34d3a38e-f9e8-4c29-94a0-4dc8a964acee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df87d71-30ef-4aea-a8e3-54aeb3d30fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3977ea74-72f4-4e84-8d17-6abe64c0d2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce9ca1f-f3eb-42ef-be91-91bc9889090e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, -3, 6.2, 'data values']\n"
     ]
    }
   ],
   "source": [
    "# Creating a series\n",
    "\n",
    "list_s=[1,2,-3,6.2,'data values']\n",
    "print(list_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea6e6a5-76ba-4f8d-806c-29fae644884d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              1\n",
       "1              2\n",
       "2             -3\n",
       "3            6.2\n",
       "4    data values\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series=pd.Series(list_s)\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8ed144d-3c98-49c7-b01c-91c04026b11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f05fea5-9382-444b-b74e-95239936892f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating new series\n",
    "\n",
    "series2=pd.Series([1,2,3,4])\n",
    "series2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1371d7f2-e43c-4637-b26d-9e9d5910f738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: object)\n"
     ]
    }
   ],
   "source": [
    "# Creating empty series\n",
    "\n",
    "empty_s=pd.Series([])\n",
    "print(empty_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70652172-728e-41d3-8fb0-a9f672a1a7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1\n",
       "b    2\n",
       "c    3\n",
       "d    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to change index value in series.\n",
    "\n",
    "series3=pd.Series([1,2,3,4],index=['a','b','c','d'])\n",
    "series3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64c68916-5860-4c3f-8b62-6204a3a8800e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1.0\n",
       "b    2.0\n",
       "c    3.0\n",
       "d    4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to change the data type in pandas.\n",
    "\n",
    "series3=pd.Series([1,2,3,4],index=['a','b','c','d'],dtype=float)\n",
    "series3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "937393ad-bb4e-4125-9a8b-9a040f2fca42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1.0\n",
       "b    2.0\n",
       "c    3.0\n",
       "d    4.0\n",
       "Name: data Values, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to add values in column.\n",
    "\n",
    "series3=pd.Series([1,2,3,4],index=['a','b','c','d'],dtype=float,name=\"data Values\")\n",
    "series3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f553aacb-a354-4b4b-bc9e-2f930ab42988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to create a series in single value(Scaler)\n",
    "\n",
    "scaler_s=pd.Series(0.5)\n",
    "scaler_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e1d3067-f4b5-4d43-9018-e0b1b7fb653f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "2    0.5\n",
       "3    0.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_s=pd.Series(0.5, index=[1,2,3])\n",
    "scaler_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10c68aae-54f5-4542-879b-e866a103fadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10.0\n",
       "b    20.0\n",
       "c    30.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to create dictionary by Series.\n",
    "\n",
    "dict_s=pd.Series({'a':10,'b':20,'c':30},dtype=float)\n",
    "dict_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eeb65a21-218e-4fba-8316-5bf6a05ab882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "4    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Understanding Operators.\n",
    "\n",
    "s4=pd.Series([1,2,3,4,5])\n",
    "s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54ed7ae5-ae7e-47ce-98d3-dccc5f6b3e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Accessing element.\n",
    "print(s4[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab0c4312-88c8-4c26-8c1e-0394a3600b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "4    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slicing an element.\n",
    "s4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cca80c3c-b30a-4950-8fe9-1bd3e71ced05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65c15b0e-e199-4c5a-8cd4-2a185f5dce78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "4    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to find maximum values in series.\n",
    "\n",
    "s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64db8473-af2b-4b5c-8c8b-153c6762f67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f160fda0-8196-47c9-8134-e26655046b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to find minimun values in series.\n",
    "min(s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c283fde-cfe0-48a6-bb90-3a8aedb6ed84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to use condition operators in series.\n",
    "\n",
    "s4[s4<3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a25c31bb-4abb-4467-aa18-9fed2325c53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    4\n",
       "4    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4[s4>3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9bc1325a-1d6d-4a4b-b8df-fd133d458832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0f1bbab1-0f76-40a5-90f1-c0d7d7c48152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "1    20\n",
       "2    30\n",
       "3    40\n",
       "4    50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s5=pd.Series([10,20,30,40,50])\n",
    "s5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "89e675f5-b512-4fc4-8746-fe72529a32c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "dtype: int64\n",
      "0    10\n",
      "1    20\n",
      "2    30\n",
      "3    40\n",
      "4    50\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(s4)\n",
    "print(s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "88caa7a5-8748-42b8-832e-7a51c3336aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11\n",
       "1    22\n",
       "2    33\n",
       "3    44\n",
       "4    55\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding two series\n",
    "\n",
    "s4+s5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a863b1b-45ee-410e-8f82-dc25917e7cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating new Series Adding \n",
    "\n",
    "s6=pd.Series([1,2,3])\n",
    "s6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2eb39cc7-cceb-4bde-abbd-2481162cf602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.0\n",
       "1    4.0\n",
       "2    6.0\n",
       "3    NaN\n",
       "4    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4+s6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d665faa6-7096-4d26-9c50-e2dec35bf322",
   "metadata": {},
   "source": [
    "# DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f8b458e-d083-454c-a8df-73107041bae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8470567c-ba56-423e-a988-a52355c22e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "emp_df=pd.DataFrame()\n",
    "print(emp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "863cabde-c30e-4d16-89c4-470eb360aedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd']\n"
     ]
    }
   ],
   "source": [
    "# Creating a list\n",
    "\n",
    "lst=['a','b','c','d']\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "71d0fc07-62cc-487d-aa27-5858bbe308ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  a\n",
       "1  b\n",
       "2  c\n",
       "3  d"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting a list into a DataFrame\n",
    "\n",
    "df1=pd.DataFrame(lst)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca235ea2-d8b2-4d6c-8897-4b6acf6d269e",
   "metadata": {},
   "source": [
    "# Multiple column we create through list of list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25670ead-8ec1-4634-95a3-316ff02ecf93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6], [2, 3, 4]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_of_lst=[[1,2,3],[4,5,6],[2,3,4]]\n",
    "lst_of_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "52b0f2a7-2e44-405a-9360-38e99b04f6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2\n",
       "0  1  2  3\n",
       "1  4  5  6\n",
       "2  2  3  4"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.DataFrame(lst_of_lst)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "47682b4f-66b3-48a6-89a6-c694fe59bc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Id': [11, 22, 33, 44], 'Name': ['Ram', 'Shyam', 'Laxman', 'Bharat']}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating pandas DataFrame from python dictionary(dictioanry of list)\n",
    "\n",
    "# Creating Dictionary\n",
    "\n",
    "dict1={'Id':[11,22,33,44],\"Name\":[\"Ram\",\"Shyam\",\"Laxman\",\"Bharat\"]}\n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "63fe01fc-1e90-450c-ac1d-eadd4051c359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Ram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>Shyam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>Laxman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Bharat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id    Name\n",
       "0  11     Ram\n",
       "1  22   Shyam\n",
       "2  33  Laxman\n",
       "3  44  Bharat"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting dictionary into DataFrame\n",
    "df3=pd.DataFrame(dict1)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73cfd951-aa2c-4700-bf1b-d65ea3bb6ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': [11, 22, 33, 44]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating pandas DataFrame from Python dictionary(dictionary of list)\n",
    "\n",
    "dict1={\"ID\":[11,22,33,44]}\n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e9cf85c-797f-4cbe-b4b8-3cfb80b123e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID\n",
       "0  11\n",
       "1  22\n",
       "2  33\n",
       "3  44"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.DataFrame(dict1)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10e4edb8-9e84-43eb-a2d6-e4d307f7c7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a': 1, 'b': 2}, {'a': 3, 'b': 4}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating pandas DataFrame from list of dictionary.\n",
    "\n",
    "\n",
    "ls_dict=[{'a':1,'b':2},{'a':3,'b':4}]\n",
    "ls_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f7b2878-05b1-4f7b-89d8-c949a1c3fcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "0  1  2\n",
       "1  3  4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4=pd.DataFrame(ls_dict)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af66a414-55a6-4583-8fa7-b114c5fb5440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a': 1, 'b': 2}, {'a': 3, 'b': 4, 'c': 5}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating two dictionary values are unequal element.\n",
    "\n",
    "\n",
    "\n",
    "ls_dict=[{'a':1,'b':2},{'a':3,'b':4,'c':5}]\n",
    "ls_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c51a879-dd67-4ec9-858b-cc5e53837333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b    c\n",
       "0  1  2  NaN\n",
       "1  3  4  5.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5=pd.DataFrame(ls_dict)\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39a3b81f-3aca-4a32-b476-3425b3957598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': 0    1\n",
       " 1    2\n",
       " 2    3\n",
       " dtype: int64,\n",
       " 'SN': 0    111\n",
       " 1    222\n",
       " 2    333\n",
       " dtype: int64}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataFrame form dictionary of series.\n",
    "# pd.Series() <----------- To create a series.\n",
    "dict_sr={\"ID\":pd.Series([1,2,3]),\"SN\":pd.Series([111,222,333])}\n",
    "dict_sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9530707-4e50-4ca1-a4c4-dd48f08f9537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID   SN\n",
       "0   1  111\n",
       "1   2  222\n",
       "2   3  333"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6=pd.DataFrame(dict_sr)\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a96247c-27b2-4049-bad5-bcaa9a9d0967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f0af634-a5bc-42b0-8ad0-3714301d0861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_csv in module pandas.io.parsers.readers:\n",
      "\n",
      "read_csv(filepath_or_buffer: 'FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str]', *, sep: 'str | None | lib.NoDefault' = <no_default>, delimiter: 'str | None | lib.NoDefault' = None, header: \"int | Sequence[int] | None | Literal['infer']\" = 'infer', names: 'Sequence[Hashable] | None | lib.NoDefault' = <no_default>, index_col: 'IndexLabel | Literal[False] | None' = None, usecols: 'list[HashableT] | Callable[[Hashable], bool] | None' = None, dtype: 'DtypeArg | None' = None, engine: 'CSVEngine | None' = None, converters: 'Mapping[Hashable, Callable] | None' = None, true_values: 'list | None' = None, false_values: 'list | None' = None, skipinitialspace: 'bool' = False, skiprows: 'list[int] | int | Callable[[Hashable], bool] | None' = None, skipfooter: 'int' = 0, nrows: 'int | None' = None, na_values: 'Sequence[str] | Mapping[str, Sequence[str]] | None' = None, keep_default_na: 'bool' = True, na_filter: 'bool' = True, verbose: 'bool' = False, skip_blank_lines: 'bool' = True, parse_dates: 'bool | Sequence[Hashable] | None' = None, infer_datetime_format: 'bool | lib.NoDefault' = <no_default>, keep_date_col: 'bool' = False, date_parser: 'Callable | lib.NoDefault' = <no_default>, date_format: 'str | None' = None, dayfirst: 'bool' = False, cache_dates: 'bool' = True, iterator: 'bool' = False, chunksize: 'int | None' = None, compression: 'CompressionOptions' = 'infer', thousands: 'str | None' = None, decimal: 'str' = '.', lineterminator: 'str | None' = None, quotechar: 'str' = '\"', quoting: 'int' = 0, doublequote: 'bool' = True, escapechar: 'str | None' = None, comment: 'str | None' = None, encoding: 'str | None' = None, encoding_errors: 'str | None' = 'strict', dialect: 'str | csv.Dialect | None' = None, on_bad_lines: 'str' = 'error', delim_whitespace: 'bool' = False, low_memory: 'bool' = True, memory_map: 'bool' = False, float_precision: \"Literal['high', 'legacy'] | None\" = None, storage_options: 'StorageOptions | None' = None, dtype_backend: 'DtypeBackend | lib.NoDefault' = <no_default>) -> 'DataFrame | TextFileReader'\n",
      "    Read a comma-separated values (csv) file into DataFrame.\n",
      "    \n",
      "    Also supports optionally iterating or breaking of the file\n",
      "    into chunks.\n",
      "    \n",
      "    Additional help can be found in the online docs for\n",
      "    `IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    filepath_or_buffer : str, path object or file-like object\n",
      "        Any valid string path is acceptable. The string could be a URL. Valid\n",
      "        URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
      "        expected. A local file could be: file://localhost/path/to/table.csv.\n",
      "    \n",
      "        If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
      "    \n",
      "        By file-like object, we refer to objects with a ``read()`` method, such as\n",
      "        a file handle (e.g. via builtin ``open`` function) or ``StringIO``.\n",
      "    sep : str, default ','\n",
      "        Character or regex pattern to treat as the delimiter. If ``sep=None``, the\n",
      "        C engine cannot automatically detect\n",
      "        the separator, but the Python parsing engine can, meaning the latter will\n",
      "        be used and automatically detect the separator from only the first valid\n",
      "        row of the file by Python's builtin sniffer tool, ``csv.Sniffer``.\n",
      "        In addition, separators longer than 1 character and different from\n",
      "        ``'\\s+'`` will be interpreted as regular expressions and will also force\n",
      "        the use of the Python parsing engine. Note that regex delimiters are prone\n",
      "        to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
      "    delimiter : str, optional\n",
      "        Alias for ``sep``.\n",
      "    header : int, Sequence of int, 'infer' or None, default 'infer'\n",
      "        Row number(s) containing column labels and marking the start of the\n",
      "        data (zero-indexed). Default behavior is to infer the column names: if no ``names``\n",
      "        are passed the behavior is identical to ``header=0`` and column\n",
      "        names are inferred from the first line of the file, if column\n",
      "        names are passed explicitly to ``names`` then the behavior is identical to\n",
      "        ``header=None``. Explicitly pass ``header=0`` to be able to\n",
      "        replace existing names. The header can be a list of integers that\n",
      "        specify row locations for a :class:`~pandas.MultiIndex` on the columns\n",
      "        e.g. ``[0, 1, 3]``. Intervening rows that are not specified will be\n",
      "        skipped (e.g. 2 in this example is skipped). Note that this\n",
      "        parameter ignores commented lines and empty lines if\n",
      "        ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
      "        data rather than the first line of the file.\n",
      "    names : Sequence of Hashable, optional\n",
      "        Sequence of column labels to apply. If the file contains a header row,\n",
      "        then you should explicitly pass ``header=0`` to override the column names.\n",
      "        Duplicates in this list are not allowed.\n",
      "    index_col : Hashable, Sequence of Hashable or False, optional\n",
      "      Column(s) to use as row label(s), denoted either by column labels or column\n",
      "      indices.  If a sequence of labels or indices is given, :class:`~pandas.MultiIndex`\n",
      "      will be formed for the row labels.\n",
      "    \n",
      "      Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
      "      column as the index, e.g., when you have a malformed file with delimiters at\n",
      "      the end of each line.\n",
      "    usecols : list of Hashable or Callable, optional\n",
      "        Subset of columns to select, denoted either by column labels or column indices.\n",
      "        If list-like, all elements must either\n",
      "        be positional (i.e. integer indices into the document columns) or strings\n",
      "        that correspond to column names provided either by the user in ``names`` or\n",
      "        inferred from the document header row(s). If ``names`` are given, the document\n",
      "        header row(s) are not taken into account. For example, a valid list-like\n",
      "        ``usecols`` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
      "        Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
      "        To instantiate a :class:`~pandas.DataFrame` from ``data`` with element order\n",
      "        preserved use ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]``\n",
      "        for columns in ``['foo', 'bar']`` order or\n",
      "        ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
      "        for ``['bar', 'foo']`` order.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the column\n",
      "        names, returning names where the callable function evaluates to ``True``. An\n",
      "        example of a valid callable argument would be ``lambda x: x.upper() in\n",
      "        ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
      "        parsing time and lower memory usage.\n",
      "    dtype : dtype or dict of {Hashable : dtype}, optional\n",
      "        Data type(s) to apply to either the whole dataset or individual columns.\n",
      "        E.g., ``{'a': np.float64, 'b': np.int32, 'c': 'Int64'}``\n",
      "        Use ``str`` or ``object`` together with suitable ``na_values`` settings\n",
      "        to preserve and not interpret ``dtype``.\n",
      "        If ``converters`` are specified, they will be applied INSTEAD\n",
      "        of ``dtype`` conversion.\n",
      "    \n",
      "        .. versionadded:: 1.5.0\n",
      "    \n",
      "            Support for ``defaultdict`` was added. Specify a ``defaultdict`` as input where\n",
      "            the default determines the ``dtype`` of the columns which are not explicitly\n",
      "            listed.\n",
      "    engine : {'c', 'python', 'pyarrow'}, optional\n",
      "        Parser engine to use. The C and pyarrow engines are faster, while the python engine\n",
      "        is currently more feature-complete. Multithreading is currently only supported by\n",
      "        the pyarrow engine.\n",
      "    \n",
      "        .. versionadded:: 1.4.0\n",
      "    \n",
      "            The 'pyarrow' engine was added as an *experimental* engine, and some features\n",
      "            are unsupported, or may not work correctly, with this engine.\n",
      "    converters : dict of {Hashable : Callable}, optional\n",
      "        Functions for converting values in specified columns. Keys can either\n",
      "        be column labels or column indices.\n",
      "    true_values : list, optional\n",
      "        Values to consider as ``True`` in addition to case-insensitive variants of 'True'.\n",
      "    false_values : list, optional\n",
      "        Values to consider as ``False`` in addition to case-insensitive variants of 'False'.\n",
      "    skipinitialspace : bool, default False\n",
      "        Skip spaces after delimiter.\n",
      "    skiprows : int, list of int or Callable, optional\n",
      "        Line numbers to skip (0-indexed) or number of lines to skip (``int``)\n",
      "        at the start of the file.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the row\n",
      "        indices, returning ``True`` if the row should be skipped and ``False`` otherwise.\n",
      "        An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
      "    skipfooter : int, default 0\n",
      "        Number of lines at bottom of file to skip (Unsupported with ``engine='c'``).\n",
      "    nrows : int, optional\n",
      "        Number of rows of file to read. Useful for reading pieces of large files.\n",
      "    na_values : Hashable, Iterable of Hashable or dict of {Hashable : Iterable}, optional\n",
      "        Additional strings to recognize as ``NA``/``NaN``. If ``dict`` passed, specific\n",
      "        per-column ``NA`` values.  By default the following values are interpreted as\n",
      "        ``NaN``: \" \", \"#N/A\", \"#N/A N/A\", \"#NA\", \"-1.#IND\", \"-1.#QNAN\", \"-NaN\", \"-nan\",\n",
      "        \"1.#IND\", \"1.#QNAN\", \"<NA>\", \"N/A\", \"NA\", \"NULL\", \"NaN\", \"None\",\n",
      "        \"n/a\", \"nan\", \"null \".\n",
      "    \n",
      "    keep_default_na : bool, default True\n",
      "        Whether or not to include the default ``NaN`` values when parsing the data.\n",
      "        Depending on whether ``na_values`` is passed in, the behavior is as follows:\n",
      "    \n",
      "        * If ``keep_default_na`` is ``True``, and ``na_values`` are specified, ``na_values``\n",
      "          is appended to the default ``NaN`` values used for parsing.\n",
      "        * If ``keep_default_na`` is ``True``, and ``na_values`` are not specified, only\n",
      "          the default ``NaN`` values are used for parsing.\n",
      "        * If ``keep_default_na`` is ``False``, and ``na_values`` are specified, only\n",
      "          the ``NaN`` values specified ``na_values`` are used for parsing.\n",
      "        * If ``keep_default_na`` is ``False``, and ``na_values`` are not specified, no\n",
      "          strings will be parsed as ``NaN``.\n",
      "    \n",
      "        Note that if ``na_filter`` is passed in as ``False``, the ``keep_default_na`` and\n",
      "        ``na_values`` parameters will be ignored.\n",
      "    na_filter : bool, default True\n",
      "        Detect missing value markers (empty strings and the value of ``na_values``). In\n",
      "        data without any ``NA`` values, passing ``na_filter=False`` can improve the\n",
      "        performance of reading a large file.\n",
      "    verbose : bool, default False\n",
      "        Indicate number of ``NA`` values placed in non-numeric columns.\n",
      "    skip_blank_lines : bool, default True\n",
      "        If ``True``, skip over blank lines rather than interpreting as ``NaN`` values.\n",
      "    parse_dates : bool, list of Hashable, list of lists or dict of {Hashable : list}, default False\n",
      "        The behavior is as follows:\n",
      "    \n",
      "        * ``bool``. If ``True`` -> try parsing the index.\n",
      "        * ``list`` of ``int`` or names. e.g. If ``[1, 2, 3]`` -> try parsing columns 1, 2, 3\n",
      "          each as a separate date column.\n",
      "        * ``list`` of ``list``. e.g.  If ``[[1, 3]]`` -> combine columns 1 and 3 and parse\n",
      "          as a single date column.\n",
      "        * ``dict``, e.g. ``{'foo' : [1, 3]}`` -> parse columns 1, 3 as date and call\n",
      "          result 'foo'\n",
      "    \n",
      "        If a column or index cannot be represented as an array of ``datetime``,\n",
      "        say because of an unparsable value or a mixture of timezones, the column\n",
      "        or index will be returned unaltered as an ``object`` data type. For\n",
      "        non-standard ``datetime`` parsing, use :func:`~pandas.to_datetime` after\n",
      "        :func:`~pandas.read_csv`.\n",
      "    \n",
      "        Note: A fast-path exists for iso8601-formatted dates.\n",
      "    infer_datetime_format : bool, default False\n",
      "        If ``True`` and ``parse_dates`` is enabled, pandas will attempt to infer the\n",
      "        format of the ``datetime`` strings in the columns, and if it can be inferred,\n",
      "        switch to a faster method of parsing them. In some cases this can increase\n",
      "        the parsing speed by 5-10x.\n",
      "    \n",
      "        .. deprecated:: 2.0.0\n",
      "            A strict version of this argument is now the default, passing it has no effect.\n",
      "    \n",
      "    keep_date_col : bool, default False\n",
      "        If ``True`` and ``parse_dates`` specifies combining multiple columns then\n",
      "        keep the original columns.\n",
      "    date_parser : Callable, optional\n",
      "        Function to use for converting a sequence of string columns to an array of\n",
      "        ``datetime`` instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "        conversion. pandas will try to call ``date_parser`` in three different ways,\n",
      "        advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "        (as defined by ``parse_dates``) as arguments; 2) concatenate (row-wise) the\n",
      "        string values from the columns defined by ``parse_dates`` into a single array\n",
      "        and pass that; and 3) call ``date_parser`` once for each row using one or\n",
      "        more strings (corresponding to the columns defined by ``parse_dates``) as\n",
      "        arguments.\n",
      "    \n",
      "        .. deprecated:: 2.0.0\n",
      "           Use ``date_format`` instead, or read in as ``object`` and then apply\n",
      "           :func:`~pandas.to_datetime` as-needed.\n",
      "    date_format : str or dict of column -> format, optional\n",
      "       Format to use for parsing dates when used in conjunction with ``parse_dates``.\n",
      "       For anything more complex, please read in as ``object`` and then apply\n",
      "       :func:`~pandas.to_datetime` as-needed.\n",
      "    \n",
      "       .. versionadded:: 2.0.0\n",
      "    dayfirst : bool, default False\n",
      "        DD/MM format dates, international and European format.\n",
      "    cache_dates : bool, default True\n",
      "        If ``True``, use a cache of unique, converted dates to apply the ``datetime``\n",
      "        conversion. May produce significant speed-up when parsing duplicate\n",
      "        date strings, especially ones with timezone offsets.\n",
      "    \n",
      "    iterator : bool, default False\n",
      "        Return ``TextFileReader`` object for iteration or getting chunks with\n",
      "        ``get_chunk()``.\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "           ``TextFileReader`` is a context manager.\n",
      "    chunksize : int, optional\n",
      "        Number of lines to read from the file per chunk. Passing a value will cause the\n",
      "        function to return a ``TextFileReader`` object for iteration.\n",
      "        See the `IO Tools docs\n",
      "        <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
      "        for more information on ``iterator`` and ``chunksize``.\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "           ``TextFileReader`` is a context manager.\n",
      "    compression : str or dict, default 'infer'\n",
      "        For on-the-fly decompression of on-disk data. If 'infer' and 'filepath_or_buffer' is\n",
      "        path-like, then detect compression from the following extensions: '.gz',\n",
      "        '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      "        (otherwise no compression).\n",
      "        If using 'zip' or 'tar', the ZIP file must contain only one data file to be read in.\n",
      "        Set to ``None`` for no decompression.\n",
      "        Can also be a dict with key ``'method'`` set\n",
      "        to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
      "        other key-value pairs are forwarded to\n",
      "        ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "        ``bz2.BZ2File``, ``zstandard.ZstdDecompressor``, ``lzma.LZMAFile`` or\n",
      "        ``tarfile.TarFile``, respectively.\n",
      "        As an example, the following could be passed for Zstandard decompression using a\n",
      "        custom compression dictionary:\n",
      "        ``compression={'method': 'zstd', 'dict_data': my_compression_dict}``.\n",
      "    \n",
      "        .. versionadded:: 1.5.0\n",
      "            Added support for `.tar` files.\n",
      "    \n",
      "        .. versionchanged:: 1.4.0 Zstandard support.\n",
      "    \n",
      "    thousands : str (length 1), optional\n",
      "        Character acting as the thousands separator in numerical values.\n",
      "    decimal : str (length 1), default '.'\n",
      "        Character to recognize as decimal point (e.g., use ',' for European data).\n",
      "    lineterminator : str (length 1), optional\n",
      "        Character used to denote a line break. Only valid with C parser.\n",
      "    quotechar : str (length 1), optional\n",
      "        Character used to denote the start and end of a quoted item. Quoted\n",
      "        items can include the ``delimiter`` and it will be ignored.\n",
      "    quoting : {0 or csv.QUOTE_MINIMAL, 1 or csv.QUOTE_ALL, 2 or csv.QUOTE_NONNUMERIC, 3 or csv.QUOTE_NONE}, default csv.QUOTE_MINIMAL\n",
      "        Control field quoting behavior per ``csv.QUOTE_*`` constants. Default is\n",
      "        ``csv.QUOTE_MINIMAL`` (i.e., 0) which implies that only fields containing special\n",
      "        characters are quoted (e.g., characters defined in ``quotechar``, ``delimiter``,\n",
      "        or ``lineterminator``.\n",
      "    doublequote : bool, default True\n",
      "       When ``quotechar`` is specified and ``quoting`` is not ``QUOTE_NONE``, indicate\n",
      "       whether or not to interpret two consecutive ``quotechar`` elements INSIDE a\n",
      "       field as a single ``quotechar`` element.\n",
      "    escapechar : str (length 1), optional\n",
      "        Character used to escape other characters.\n",
      "    comment : str (length 1), optional\n",
      "        Character indicating that the remainder of line should not be parsed.\n",
      "        If found at the beginning\n",
      "        of a line, the line will be ignored altogether. This parameter must be a\n",
      "        single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
      "        fully commented lines are ignored by the parameter ``header`` but not by\n",
      "        ``skiprows``. For example, if ``comment='#'``, parsing\n",
      "        ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in ``'a,b,c'`` being\n",
      "        treated as the header.\n",
      "    encoding : str, optional, default 'utf-8'\n",
      "        Encoding to use for UTF when reading/writing (ex. ``'utf-8'``). `List of Python\n",
      "        standard encodings\n",
      "        <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "           When ``encoding`` is ``None``, ``errors='replace'`` is passed to\n",
      "           ``open()``. Otherwise, ``errors='strict'`` is passed to ``open()``.\n",
      "           This behavior was previously only the case for ``engine='python'``.\n",
      "    \n",
      "        .. versionchanged:: 1.3.0\n",
      "    \n",
      "           ``encoding_errors`` is a new argument. ``encoding`` has no longer an\n",
      "           influence on how encoding errors are handled.\n",
      "    \n",
      "    encoding_errors : str, optional, default 'strict'\n",
      "        How encoding errors are treated. `List of possible values\n",
      "        <https://docs.python.org/3/library/codecs.html#error-handlers>`_ .\n",
      "    \n",
      "        .. versionadded:: 1.3.0\n",
      "    \n",
      "    dialect : str or csv.Dialect, optional\n",
      "        If provided, this parameter will override values (default or not) for the\n",
      "        following parameters: ``delimiter``, ``doublequote``, ``escapechar``,\n",
      "        ``skipinitialspace``, ``quotechar``, and ``quoting``. If it is necessary to\n",
      "        override values, a ``ParserWarning`` will be issued. See ``csv.Dialect``\n",
      "        documentation for more details.\n",
      "    on_bad_lines : {'error', 'warn', 'skip'} or Callable, default 'error'\n",
      "        Specifies what to do upon encountering a bad line (a line with too many fields).\n",
      "        Allowed values are :\n",
      "    \n",
      "        - ``'error'``, raise an Exception when a bad line is encountered.\n",
      "        - ``'warn'``, raise a warning when a bad line is encountered and skip that line.\n",
      "        - ``'skip'``, skip bad lines without raising or warning when they are encountered.\n",
      "    \n",
      "        .. versionadded:: 1.3.0\n",
      "    \n",
      "        .. versionadded:: 1.4.0\n",
      "    \n",
      "            - Callable, function with signature\n",
      "              ``(bad_line: list[str]) -> list[str] | None`` that will process a single\n",
      "              bad line. ``bad_line`` is a list of strings split by the ``sep``.\n",
      "              If the function returns ``None``, the bad line will be ignored.\n",
      "              If the function returns a new ``list`` of strings with more elements than\n",
      "              expected, a ``ParserWarning`` will be emitted while dropping extra elements.\n",
      "              Only supported when ``engine='python'``\n",
      "    \n",
      "    delim_whitespace : bool, default False\n",
      "        Specifies whether or not whitespace (e.g. ``' '`` or ``'\\t'``) will be\n",
      "        used as the ``sep`` delimiter. Equivalent to setting ``sep='\\s+'``. If this option\n",
      "        is set to ``True``, nothing should be passed in for the ``delimiter``\n",
      "        parameter.\n",
      "    low_memory : bool, default True\n",
      "        Internally process the file in chunks, resulting in lower memory use\n",
      "        while parsing, but possibly mixed type inference.  To ensure no mixed\n",
      "        types either set ``False``, or specify the type with the ``dtype`` parameter.\n",
      "        Note that the entire file is read into a single :class:`~pandas.DataFrame`\n",
      "        regardless, use the ``chunksize`` or ``iterator`` parameter to return the data in\n",
      "        chunks. (Only valid with C parser).\n",
      "    memory_map : bool, default False\n",
      "        If a filepath is provided for ``filepath_or_buffer``, map the file object\n",
      "        directly onto memory and access the data directly from there. Using this\n",
      "        option can improve performance because there is no longer any I/O overhead.\n",
      "    float_precision : {'high', 'legacy', 'round_trip'}, optional\n",
      "        Specifies which converter the C engine should use for floating-point\n",
      "        values. The options are ``None`` or ``'high'`` for the ordinary converter,\n",
      "        ``'legacy'`` for the original lower precision pandas converter, and\n",
      "        ``'round_trip'`` for the round-trip converter.\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "        are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "        URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "        forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "        details, and for more examples on storage options refer `here\n",
      "        <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "        highlight=storage_options#reading-writing-remote-files>`_.\n",
      "    \n",
      "        .. versionadded:: 1.2\n",
      "    \n",
      "    dtype_backend : {'numpy_nullable', 'pyarrow'}, default 'numpy_nullable'\n",
      "        Back-end data type applied to the resultant :class:`DataFrame`\n",
      "        (still experimental). Behaviour is as follows:\n",
      "    \n",
      "        * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\n",
      "          (default).\n",
      "        * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\n",
      "          DataFrame.\n",
      "    \n",
      "        .. versionadded:: 2.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or TextFileReader\n",
      "        A comma-separated values (csv) file is returned as two-dimensional\n",
      "        data structure with labeled axes.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "    read_table : Read general delimited file into DataFrame.\n",
      "    read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c99f61a-89f0-4992-bc92-9562e04d8f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Class</th>\n",
       "      <th>Study hrs</th>\n",
       "      <th>Sleeping hrs</th>\n",
       "      <th>Social Media usage hrs</th>\n",
       "      <th>Mobile Games hrs</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1006</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1007</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1008</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1009</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1010</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student ID  Class  Study hrs  Sleeping hrs  Social Media usage hrs  \\\n",
       "0        1001     10          2             9                       3   \n",
       "1        1002     10          6             8                       2   \n",
       "2        1003     10          3             8                       2   \n",
       "3        1004     11          0            10                       1   \n",
       "4        1005     11          4             7                       2   \n",
       "5        1006     11         10             7                       0   \n",
       "6        1007     12          4             6                       0   \n",
       "7        1008     12         10             6                       2   \n",
       "8        1009     12          2             8                       2   \n",
       "9        1010     12          6             9                       1   \n",
       "\n",
       "   Mobile Games hrs  Percentage  \n",
       "0                 5          50  \n",
       "1                 0          80  \n",
       "2                 4          60  \n",
       "3                 5          45  \n",
       "4                 0          75  \n",
       "5                 0          96  \n",
       "6                 0          80  \n",
       "7                 0          90  \n",
       "8                 4          60  \n",
       "9                 0          85  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"D:\\\\Data_Analysis_04-06PM\\\\student_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e55520dc-ae5e-4657-86a6-06653b77f12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top 10 IT Companies in India</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Infosys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tech Mahindra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HCL Technologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L&amp;T Infotech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mindtree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mphasis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Oracle Financial Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rotla India</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Top 10 IT Companies in India\n",
       "0                          TCS\n",
       "1                      Infosys\n",
       "2                Tech Mahindra\n",
       "3                        Wipro\n",
       "4             HCL Technologies\n",
       "5                 L&T Infotech\n",
       "6                     Mindtree\n",
       "7                      Mphasis\n",
       "8    Oracle Financial Services\n",
       "9                  Rotla India"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to import series -1-D(Data)\n",
    "\n",
    "pd.read_csv(\"D:\\\\Data_Analysis_04-06PM\\\\Companies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98fcb505-8e23-4da1-995f-57820860e47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to check your current location of your pandas file\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd614a84-85b0-4c74-ab22-92906c3fc68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Data_Analysis_04-06PM\\2. Pandas\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30e0d6e-c394-4d5f-b3ed-3fd9803d5920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
